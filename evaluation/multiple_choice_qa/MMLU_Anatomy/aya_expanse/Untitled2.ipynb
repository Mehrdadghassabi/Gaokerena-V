{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4CvKVSfztm9y",
        "outputId": "4000bca8-0f68-4ea8-cb46-cae2f69e7143"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.3.2-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.10.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.13)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.3.2-py3-none-any.whl (485 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.4/485.4 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, dill, multiprocess, datasets\n",
            "Successfully installed datasets-3.3.2 dill-0.3.8 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "import os\n",
        "from datasets import Dataset\n",
        "from tqdm import tqdm\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import pandas as pd\n",
        "from huggingface_hub import login\n",
        "import torch\n",
        "import random\n",
        "import re"
      ],
      "metadata": {
        "id": "pecWXN7Ytyqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "login()"
      ],
      "metadata": {
        "id": "0-NodOSONEdU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title prompts\n",
        "prompt_get_part = f'''\n",
        "\n",
        "## پرسش\n",
        "{{question}} \\n\n",
        "این یک پرسش پزشکی است برای طبقه بندی پرسش یکی از موضوعات زیر را انتخاب کنید به گونه ای که بیشترین تطابق را با پرسش داشته باشد\n",
        "\n",
        "Topic List = [\n",
        "    \"Part 1: The Profession of Medicine\",\n",
        "    \"Part 2: Cardinal Manifestations and Presentation of Diseases\",\n",
        "    \"Part 3: Pharmacology\",\n",
        "    \"Part 4: Oncology and Hematology\",\n",
        "    \"Part 5: Infectious Diseases\",\n",
        "    \"Part 6: Disorders of the Cardiovascular System\",\n",
        "    \"Part 7: Disorders of the Respiratory System\",\n",
        "    \"Part 8: Critical Care Medicine\",\n",
        "    \"Part 9: Disorders of the Kidney and Urinary Tract\",\n",
        "    \"Part 10: Disorders of the Gastrointestinal System\",\n",
        "    \"Part 11: Immune-Mediated, Inflammatory, and Rheumatologic Disorders\",\n",
        "    \"Part 12: Endocrinology and Metabolism\",\n",
        "    \"Part 13: Neurologic Disorders\",\n",
        "    \"Part 14: Poisoning, Drug Overdose, and Envenomation\",\n",
        "    \"Part 15: Disorders Associated with Environmental Exposures\",\n",
        "    \"Part 16: Genes, the Environment, and Disease\",\n",
        "    \"Part 17: Global Medicine\",\n",
        "    \"Part 18: Aging\",\n",
        "    \"Part 19: Consultative Medicine\",\n",
        "    \"Part 20: Frontiers\"\n",
        "]\n",
        "به عنوان پاسخ تنها و تنها یک عدد برگردانید به گونه ای که بیشترین تطابق را با پرسش داشته باشد.\n",
        "'''\n",
        "\n",
        "prompt_eval = f'''\n",
        "## پرسش\n",
        "{{question}} \\n\n",
        "\n",
        "## گزینه ها\n",
        "{{choices}} \\n\n",
        "این یک پرسش پزشکی است به همراه گزینه هایی که میتوانید انتخاب کنید. به این پرسش قدم به قدم فکر کرده و پاسخ خود را به صورت زیر بیان کنید:\n",
        "پاسخ تولید شده توسط مدل که قدم به قدم به آن فکر شده. بنابراین پاسخ نهایی [پاسخ نهایی مدل (e.g. A,B,C,D)] میباشد. به عنوان مثال [A]\n",
        "\\n\n",
        "'''\n",
        "\n",
        "prompt_eval_bare = f'''\n",
        "به پرسش زیر به پاسخ بدهید و تنها از زبان فارسی استفاده کنید!\n",
        "## پرسش\n",
        "{{question}} \\n\n",
        "\n",
        "## گزینه ها\n",
        "{{choices}} \\n\n",
        "\n",
        "\\n\n",
        "'''\n",
        "\n",
        "prompt_eval_bare_fully = f'''\n",
        "{{question}} \\n\n",
        "{{choices}}\n",
        "'''\n",
        "\n",
        "prompt_eval_bare_fully_with_examples = f'''\n",
        "{{examples}} \\n\n",
        "{{question}} \\n\n",
        "{{choices}}\n",
        "'''\n",
        "\n",
        "prompt_eval_with_examples = f'''\n",
        "## نمونه ها\n",
        "{{examples}}\n",
        "\n",
        "Above are examples for medical Q&A.\n",
        "\n",
        "## پرسش\n",
        "{{question}} \\n\n",
        "\n",
        "## گزینه ها\n",
        "{{choices}} \\n\n",
        "\n",
        "این یک پرسش پزشکی است به همراه گزینه هایی که میتوانید انتخاب کنید. به این پرسش قدم به قدم فکر کرده و پاسخ خود را به صورت زیر بیان کنید:\n",
        "پاسخ تولید شده توسط مدل که قدم به قدم به آن فکر شده. بنابراین پاسخ نهایی [پاسخ نهایی مدل (e.g. A,B,C,D)] میباشد. به عنوان مثال [A]\n",
        "\\n\n",
        "'''\n",
        "\n",
        "prompt_eval_context_bare = f'''\n",
        "{{context}} \\n\n",
        "{{question}} \\n\n",
        "{{choices}}\n",
        "'''\n",
        "prompt_eval_with_context = f'''\n",
        "## Context\n",
        "{{context}} \\n\n",
        "\n",
        "## پرسش\n",
        "{{question}} \\n\n",
        "\n",
        "## گزینه ها\n",
        "{{choices}} \\n\n",
        "این یک متن از یک کتاب مرجع است به همراه یک پرسش پزشکی و گزینه هایی که میتوانید انتخاب کنید. به این پرسش قدم به قدم فکر کرده و پاسخ خود را به صورت زیر بیان کنید:\n",
        "پاسخ تولید شده توسط مدل که قدم به قدم به آن فکر شده. بنابراین پاسخ نهایی [پاسخ نهایی مدل (e.g. A,B,C,D)] میباشد. به عنوان مثال [A]\n",
        "\\n '''\n",
        "\n",
        "prompt_eval_with_context_and_examples = f'''\n",
        "## نمونه ها\n",
        "{{examples}}\n",
        "در بالا نمونه هایی از پرسش پاسخ پزشکی آورده شده است.\n",
        "\n",
        "## متن\n",
        "{{context}} \\n\n",
        "\n",
        "## پرسش\n",
        "{{question}} \\n\n",
        "\n",
        "## گزینه ها\n",
        "{{choices}} \\n\n",
        "\n",
        "این یک پرسش پزشکی است به همراه گزینه هایی که میتوانید انتخاب کنید. به این پرسش قدم به قدم فکر کرده و پاسخ خود را به صورت زیر بیان کنید:\n",
        "پاسخ تولید شده توسط مدل که قدم به قدم به آن فکر شده. بنابراین پاسخ نهایی [پاسخ نهایی مدل (e.g. A,B,C,D)] میباشد. به عنوان مثال [A]\n",
        "\\n '''\n",
        "\n",
        "prompt_example = f'''\n",
        "## پرسش\n",
        "{{question}} \\n\n",
        "\n",
        "## گزینه ها\n",
        "{{choices}} \\n\n",
        "\n",
        "## پاسخ\n",
        "{{answer}} \\n\n",
        "'''"
      ],
      "metadata": {
        "cellView": "form",
        "id": "5y6BMoECt5Nb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title utility\n",
        "# Set openai key if using gpt4o as engine.\n",
        "#os.environ['OPENAI_API_KEY'] = \"OPEN AI KEY HERE\"\n",
        "def extract_samples(task, numShot, model_prompt):\n",
        "    questions, answer_choices, correct_answers = task_load(task, 'train')\n",
        "    example_indexes = random.sample(range(len(questions)), numShot)\n",
        "    example_list = []\n",
        "    for i in example_indexes:\n",
        "        example_list.append(model_prompt.format(question=questions[i], choices=format_choices(answer_choices[i]), answer=correct_answers[i]))\n",
        "    return example_list\n",
        "\n",
        "def get_ds_from_df(df,task):\n",
        "    if task == 'kopp':\n",
        "       df['Question'] = df['Question'].astype(str)\n",
        "       df['Option1'] = df['Option1'].astype(str)\n",
        "       df['Option2'] = df['Option2'].astype(str)\n",
        "       df['Option3'] = df['Option3'].astype(str)\n",
        "       df['Option4'] = df['Option4'].astype(str)\n",
        "       df['Topic'] = df['Topic'].astype(str)\n",
        "       df['Source'] = df['Source'].astype(str)\n",
        "       df['Correct answer'] = df['Correct answer'].astype(str)\n",
        "       ds = Dataset.from_pandas(df)\n",
        "       return ds\n",
        "    elif \"mmlu\" in task:\n",
        "       df['question'] = df['question'].astype(str)\n",
        "       df['option1'] = df['option1'].astype(str)\n",
        "       df['option2'] = df['option2'].astype(str)\n",
        "       df['Option3'] = df['option3'].astype(str)\n",
        "       df['option4'] = df['option4'].astype(str)\n",
        "       df['answer'] = df['answer'].astype(str)\n",
        "       ds = Dataset.from_pandas(df)\n",
        "       return ds\n",
        "    else:\n",
        "       raise Exception(\"TASK NOT FOUND\")\n",
        "\n",
        "def resume_the_test(question_list, answer_choices_list, correct_answer_list,bgn):\n",
        "    question_list = question_list[bgn:]\n",
        "    answer_choices_list = answer_choices_list[bgn:]\n",
        "    correct_answer_list = correct_answer_list[bgn:]\n",
        "    for i, (question, answer_choices, correct_answer) in tqdm(enumerate(zip(question_list, answer_choices_list, correct_answer_list))):\n",
        "            context = \"\"\n",
        "            if NSHOT == 0:\n",
        "               prompt = prompt_eval_bare\n",
        "            else:\n",
        "               prompt = prompt_eval_bare_fully_with_examples\n",
        "\n",
        "            if NSHOT != 0:\n",
        "                examples = extract_samples(TASK, NSHOT, prompt_example)\n",
        "                model_prompt = prompt.format(\n",
        "                    question=question,\n",
        "                    choices=format_choices(answer_choices),\n",
        "                    examples = (\"\\n\").join(examples),\n",
        "                    context = filterContext(context)\n",
        "                )\n",
        "            else:\n",
        "                model_prompt = prompt.format(question=question, choices=format_choices(answer_choices), context = filterContext(context))\n",
        "\n",
        "            AI_answer = run_inference(model_prompt, ENGINE, ENGINE_TEMPERATURE, MAX_TOKEN_OUTPUT, tokenizer, model, local=True)\n",
        "            file_path = 'fa_aya_result.xlsx'\n",
        "            append_record_to_excel(file_path, question, answer_choices,\n",
        "                           correct_answer, model_prompt, AI_answer)\n",
        "\n",
        "            if i == STOP_GEN-1:\n",
        "                break\n",
        "\n",
        "def append_record_to_excel(file_path, Question, question_choices,\n",
        "                           correct_answer, model_prompt, AI_answer):\n",
        "    new_record = {\n",
        "        'Question': Question,\n",
        "        'question_choices': question_choices,\n",
        "        'correct_answer': correct_answer,\n",
        "        'model_prompt':  model_prompt,\n",
        "        'AI_answer': AI_answer\n",
        "    }\n",
        "    new_record_df = pd.DataFrame([new_record])\n",
        "    try:\n",
        "        existing_df = pd.read_excel(file_path)\n",
        "        updated_df = pd.concat([existing_df, new_record_df], ignore_index=True)\n",
        "    except FileNotFoundError:\n",
        "        updated_df = new_record_df\n",
        "\n",
        "    updated_df.to_excel(file_path, index=False)\n",
        "\n",
        "def format_choices(choices):\n",
        "    a = zip(list(choices.keys()), choices.values())\n",
        "    final_answers = []\n",
        "    for x,y in a:\n",
        "        final_answers.append(f'[{x}] : {y}')\n",
        "    return \"\\n\".join(final_answers)\n",
        "\n",
        "def format_examples(examples):\n",
        "    formatted_examples = []\n",
        "    for row in examples:\n",
        "        example = f'## Question {row[\"question\"]} \\n ## Answer {row[\"answer\"]}'\n",
        "        formatted_examples.append(example)\n",
        "    return \"\\n\".join(formatted_examples)\n",
        "\n",
        "def task_load(task, split):\n",
        "    if task==\"kopp\":\n",
        "        df = pd.read_excel(task+'.xlsx')\n",
        "        ds =get_ds_from_df(df,task)\n",
        "        questions = [ds[i]['Question'] for i in range(len(ds))]\n",
        "        answer_choices = [{\"A\": ds[i]['Option1'], \"B\": ds[i]['Option2'], \"C\": ds[i]['Option3'], \"D\": ds[i]['Option4']} for i in range(len(ds))]\n",
        "        correct_answers = [chr(int(ds[i]['Correct answer'])+64) for i in range(len(ds))]\n",
        "        return questions, answer_choices, correct_answers\n",
        "    elif \"mmlu\" in task:\n",
        "        df = pd.read_excel(task+'_fa.xlsx')\n",
        "        ds =get_ds_from_df(df,task)\n",
        "        questions = [ds[i]['question'] for i in range(len(ds))]\n",
        "        answer_choices = [{\"A\": ds[i]['option1'], \"B\": ds[i]['option2'], \"C\": ds[i]['option3'], \"D\": ds[i]['option4']} for i in range(len(ds))]\n",
        "        correct_answers = [chr(int(ds[i]['answer'])+64) for i in range(len(ds))]\n",
        "        return questions, answer_choices, correct_answers\n",
        "    else:\n",
        "        raise Exception(\"TASK NOT FOUND\")\n",
        "\n",
        "def filterContext(context):\n",
        "    end_tag = \"</end>\"\n",
        "    if end_tag in context:\n",
        "        return context.split(end_tag)[0] + end_tag\n",
        "    return context\n",
        "\n",
        "def run_inference(content, engine, temp=0.0000001, max_tokens_output=200, tokenizer=None, model=None, local=False):\n",
        "    if local:\n",
        "        messages = [{\"role\": \"user\", \"content\": f\"{content}\"}]\n",
        "        inputs = tokenizer.apply_chat_template(messages, add_generation_prompt=True, return_tensors=\"pt\").to('cuda:0')\n",
        "        with torch.no_grad():\n",
        "             outputs = model.generate(inputs, max_new_tokens=max_tokens_output, do_sample = True, temperature=temp)\n",
        "             text = tokenizer.batch_decode(outputs)[0]\n",
        "             answer = re.sub(r'<\\|END_OF_TURN_TOKEN\\|>$', '', text.split(\"model\")[-1].split(\"<|CHATBOT_TOKEN|>\")[1])\n",
        "             return answer\n",
        "    else:\n",
        "        client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
        "        messages = [{\"role\": \"user\", \"content\": f\"{content}\"}]\n",
        "        response = client.chat.completions.create(\n",
        "            model=engine,\n",
        "            messages=messages,\n",
        "            temperature=temp,\n",
        "            max_tokens=max_tokens_output,\n",
        "            frequency_penalty=0.0\n",
        "        )\n",
        "        response_text = response.choices[0].message.content\n",
        "        return response_text"
      ],
      "metadata": {
        "cellView": "form",
        "id": "9XIysPufuy4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title model setting\n",
        "print(\"RUNNING NORMAL IMPLEMENTATION\")\n",
        "ENGINE = \"CohereForAI/aya-expanse-8b\"\n",
        "SPLIT = \"test\"\n",
        "ENGINE_TEMPERATURE = 0.000000001\n",
        "MAX_TOKEN_OUTPUT = 1024\n",
        "NSHOT = 0\n",
        "STOP_GEN = 10000000 ## For testing purposes; stop generating after {STOP_GEN} amount of test-questions\n",
        "TASK = 'mmlu-professional_medicine' # Options [\"kopp\", 'mmlu-anatomy', 'mmlu-professional_medicine', 'mmlu-college_biology', 'mmlu-college_medicine', 'mmlu-clinical_knowledge', 'mmlu-medical_genetics']\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "dtype = torch.bfloat16\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"CohereForAI/aya-expanse-8b\",\n",
        "    torch_dtype=dtype,\n",
        "    device_map=device\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"CohereForAI/aya-expanse-8b\")\n",
        "model.eval()\n",
        "## OUTPUT RUN INFO:\n",
        "print(\"Model Running: \" + ENGINE)"
      ],
      "metadata": {
        "id": "GE6Cule00IUk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Load the test\n",
        "question_list, answer_choices_list, correct_answer_list = task_load(TASK, SPLIT)\n",
        "print(f\"{TASK} loaded succesfully. Now conducting evaluation on {len(question_list)} samples.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EpKfarHdu7qF",
        "outputId": "6fe87f43-81fb-4858-e265-1df505f1e0a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mmlu-anatomy loaded succesfully. Now conducting evaluation on 135 samples.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Since google colab usage time is limited & this test takes days to complete\n",
        "#  we need to concatenate the result of many session to get the final result\n",
        "#   so set the bgn variable to number of question that has been solved in previous sessions\n",
        "resume_the_test(question_list, answer_choices_list, correct_answer_list,bgn = 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xat0VJ1zvAsy",
        "outputId": "e6a5fff9-41c7-4936-f690-9f5056a59b9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "135it [13:04,  5.81s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# append AI_chosen_answer column manually to the excel file\n",
        "#  then measure the accuracy\n",
        "df = pd.read_excel('fa_aya_result.xlsx')\n",
        "number_of_questions = 0\n",
        "number_of_invalid_answers = 0\n",
        "number_of_correct_answers = 0\n",
        "for index,row in df.iterrows():\n",
        "    number_of_questions += 1\n",
        "    AI_chosen_answer = row['AI_chosen_answer']\n",
        "    correct_answer = row['correct_answer']\n",
        "    if AI_chosen_answer == 'invalid':\n",
        "       number_of_invalid_answers += 1\n",
        "    elif AI_chosen_answer == correct_answer:\n",
        "       number_of_correct_answers += 1\n",
        "print('#Questions: '+str(number_of_questions))\n",
        "print('#Correct answers: '+str(number_of_correct_answers))\n",
        "print('#Invalid answers: '+str(number_of_invalid_answers))\n",
        "print('Accuracy: '+str(number_of_correct_answers/number_of_questions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iyZmhMDgvBTD",
        "outputId": "f8ad2af2-0987-43ec-c499-3cd07d699644"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#Questions: 135\n",
            "#Correct answers: 55\n",
            "#Invalid answers: 1\n",
            "Accuracy: 0.4074074074074074\n"
          ]
        }
      ]
    }
  ]
}