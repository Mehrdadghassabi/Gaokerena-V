{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b8dTNgW-1Gws"
      },
      "outputs": [],
      "source": [
        "!pip install datasets\n",
        "!pip install flash-attn --no-build-isolation\n",
        "!pip install wandb\n",
        "!pip install trl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bhAt_n0T1N1Y"
      },
      "outputs": [],
      "source": [
        "!wandb login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HqaZtriI1Pjk"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import login\n",
        "login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6lM8iVzu1Q81"
      },
      "outputs": [],
      "source": [
        "import wandb\n",
        "\n",
        "wandb.init(\n",
        "    project=\"gaokerena\",\n",
        "    name=\"instruction_tuning\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y3eBBe9n1VoT"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    TrainerCallback,\n",
        ")\n",
        "from peft import LoraConfig, PeftModel\n",
        "from trl import SFTTrainer, SFTConfig\n",
        "\n",
        "BASE_MODEL_ID = \"CohereForAI/aya-expanse-8b\"\n",
        "PRETRAINED_MODEL_ID = \"gaokerena/pretrained\"\n",
        "DATASET_REPO = \"gaokerena/MF3QA\"\n",
        "DATASET_SPLIT = \"train\"\n",
        "WORKING_REPO_ID = \"gaokerena/instruction_tuned\"\n",
        "\n",
        "HYPER_PARAMS = {\n",
        "    \"run_name\": \"pretraining\",\n",
        "    \"output_dir\": \"outputs\",\n",
        "    \"num_train_epochs\": 1,\n",
        "    \"per_device_train_batch_size\": 2,\n",
        "    \"gradient_accumulation_steps\": 16,\n",
        "    \"optim\": \"adamw_torch\",\n",
        "    \"logging_steps\": 4,\n",
        "    \"save_strategy\": \"steps\",\n",
        "    \"save_total_limit\": 1,\n",
        "    \"learning_rate\": 5e-4,\n",
        "    \"bf16\": True,\n",
        "    \"max_grad_norm\": 0.3,\n",
        "    \"warmup_ratio\": 0.03,\n",
        "    \"lr_scheduler_type\": \"cosine\",\n",
        "    \"weight_decay\": 0.5,\n",
        "    \"report_to\": \"wandb\",\n",
        "    \"gradient_checkpointing\": True,\n",
        "    \"gradient_checkpointing_kwargs\": {\"use_reentrant\": False},\n",
        "    \"hub_model_id\": WORKING_REPO_ID,\n",
        "    \"dataloader_persistent_workers\": True,\n",
        "    \"dataloader_num_workers\": 4,\n",
        "    \"max_seq_length\": 1024,\n",
        "    \"packing\": False,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gtCZL4aX2N4A"
      },
      "outputs": [],
      "source": [
        "dataset = load_dataset(DATASET_REPO, split=DATASET_SPLIT)\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wLKaGHgB3wid"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_ID)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    BASE_MODEL_ID,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map=\"cuda\",\n",
        "    low_cpu_mem_usage=True,\n",
        "    attn_implementation=\"flash_attention_2\"\n",
        ")\n",
        "model = PeftModel.from_pretrained(model, PRETRAINED_MODEL_ID)\n",
        "model = model.merge_and_unload()\n",
        "tokenizer.pad_token = tokenizer.eos_token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UJsLh6BZ323b"
      },
      "outputs": [],
      "source": [
        "lora_config = LoraConfig(\n",
        "    lora_alpha=2,\n",
        "    lora_dropout=0.4,\n",
        "    r=2,\n",
        "    bias=\"none\",\n",
        "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
        "    task_type=\"CAUSAL_LM\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FZrjzl353_9P"
      },
      "outputs": [],
      "source": [
        "class PushToHubCallback(TrainerCallback):\n",
        "    def on_save(self, args, state, control, **kwargs):\n",
        "        kwargs[\"model\"].push_to_hub(repo_id=WORKING_REPO_ID, commit_message=f\"Checkpoint at step {state.global_step}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T3HFfvki4E6I"
      },
      "outputs": [],
      "source": [
        "args = SFTConfig(\n",
        "    **HYPER_PARAMS\n",
        ")\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=dataset,\n",
        "    peft_config=lora_config,\n",
        "    callbacks=[PushToHubCallback],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nupreAzK4RVy"
      },
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}