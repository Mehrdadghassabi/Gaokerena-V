{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jrQUV4wz_CvY"
      },
      "outputs": [],
      "source": [
        "!pip install datasets\n",
        "!pip install flash-attn --no-build-isolation\n",
        "!pip install wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jvcFPpiG_IQn"
      },
      "outputs": [],
      "source": [
        "!wandb login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4B15IbIL_Iyf"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import login\n",
        "login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ggdqW_ga_MOJ"
      },
      "outputs": [],
      "source": [
        "import wandb\n",
        "\n",
        "wandb.init(\n",
        "    project=\"gaokerena\",\n",
        "    name=\"pretraining\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q0OEbrLs_TWN"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM,\n",
        "    DataCollatorForLanguageModeling,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    TrainerCallback\n",
        ")\n",
        "from peft import (\n",
        "    LoraConfig,\n",
        "    get_peft_model\n",
        ")\n",
        "\n",
        "MODEL_ID = \"CohereForAI/aya-expanse-8b\"\n",
        "DATASET_REPO = \"gaokerena/mediacal_corpus\"\n",
        "DATASET_SPLIT = \"train[:60%]\"\n",
        "WORKING_REPO_ID = \"gaokerena/pretrained\"\n",
        "\n",
        "CONTEXT_LENGTH = 1024\n",
        "\n",
        "HYPER_PARAMS = {\n",
        "    \"output_dir\": \"outputs\",\n",
        "    \"num_train_epochs\": 1,\n",
        "    \"per_device_train_batch_size\": 2,\n",
        "    \"gradient_accumulation_steps\": 16,\n",
        "    \"optim\": \"adamw_torch\",\n",
        "    \"logging_steps\": 4,\n",
        "    \"save_strategy\": \"steps\",\n",
        "    \"save_steps\": 1000,\n",
        "    \"save_total_limit\": 1,\n",
        "    \"learning_rate\": 5e-4,\n",
        "    \"max_grad_norm\": 0.3,\n",
        "    \"warmup_ratio\": 0.03,\n",
        "    \"lr_scheduler_type\": \"cosine\",\n",
        "    \"weight_decay\": 0.1,\n",
        "    \"report_to\": \"wandb\",\n",
        "    \"gradient_checkpointing\": True,\n",
        "    \"gradient_checkpointing_kwargs\": {\"use_reentrant\": False},\n",
        "    \"hub_model_id\": WORKING_REPO_ID,\n",
        "    \"dataloader_persistent_workers\": True,\n",
        "    \"dataloader_num_workers\": 4,\n",
        "    \"label_names\": [\"labels\"],\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iOTbx8-_AaHR"
      },
      "outputs": [],
      "source": [
        "dataset = load_dataset(DATASET_REPO, split=DATASET_SPLIT)\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tk3ELTgHOuH0"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
        "\n",
        "def tokenize(element):\n",
        "    outputs = tokenizer(\n",
        "        element[\"content\"],\n",
        "        truncation=True,\n",
        "        max_length=CONTEXT_LENGTH,\n",
        "        return_overflowing_tokens=True,\n",
        "        return_length=True,\n",
        "        padding=True\n",
        "    )\n",
        "    input_ids = []\n",
        "    for element_input_ids in outputs[\"input_ids\"]:\n",
        "        input_ids.append(element_input_ids)\n",
        "    return {\"input_ids\": input_ids, \"labels\": input_ids}\n",
        "\n",
        "tokenized_dataset = dataset.map(\n",
        "    tokenize, batched=True, remove_columns=dataset.column_names\n",
        ")\n",
        "tokenized_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h2C51zbWO4FP"
      },
      "outputs": [],
      "source": [
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_ID,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map=\"cuda\",\n",
        "    low_cpu_mem_usage=True,\n",
        "    attn_implementation=\"flash_attention_2\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "tUq-imYpPCHp"
      },
      "outputs": [],
      "source": [
        "data_collator = DataCollatorForLanguageModeling(tokenizer, mlm=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "XVh8UtXuPEEl"
      },
      "outputs": [],
      "source": [
        "lora_config = LoraConfig(\n",
        "    lora_alpha=16,\n",
        "    lora_dropout=0.05,\n",
        "    r=8,\n",
        "    bias=\"none\",\n",
        "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
        "    task_type=\"CAUSAL_LM\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_eTApliPH9x"
      },
      "outputs": [],
      "source": [
        "model = get_peft_model(model, lora_config)\n",
        "model.print_trainable_parameters()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BVP5Xu7DPVjU"
      },
      "outputs": [],
      "source": [
        "class PushToHubCallback(TrainerCallback):\n",
        "    def on_save(self, args, state, control, **kwargs):\n",
        "        kwargs[\"model\"].push_to_hub(repo_id=WORKING_REPO_ID, commit_message=f\"Checkpoint at step {state.global_step}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "XxEMyw5nPkRO"
      },
      "outputs": [],
      "source": [
        "args = TrainingArguments(\n",
        "    **HYPER_PARAMS\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=tokenized_dataset,\n",
        "    data_collator=data_collator,\n",
        "    callbacks=[PushToHubCallback],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5BvdjCdISv3g"
      },
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
